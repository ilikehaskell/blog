{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Friendly Python Clojures in an automatic Text Annotator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "While creating some pipelines for automatic text annotation, I encountered a bug that made me realise that I didn't understand a basic block of programming.\n",
    "If you know what closures are and how to use them, you can skip this post. \n",
    "Still here? Then I'll reconstruct some [SpaCy](https://spacy.io/) and [skweak](https://github.com/NorskRegnesentral/skweak) functionalities for you so I can give you some context in which you may also need to use closures."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SpaCy objects\n",
    "\n",
    "Central to the SpaCy package is the `Doc` objects (short for document). It's a neatly way to pack data for NLP and if it doesn't provide what you need out of the box, you can [always extend it's functionalities](https://spacy.io/usage/processing-pipelines#custom-components-attributes) to match your usecase."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from typing import Callable, Generator, Iterable\n",
    "\n",
    "class Doc:\n",
    "    def __init__(self, text) -> None:\n",
    "        self.text = text\n",
    "        self.tokens: List[str] = text.split()\n",
    "        self.spans: Span = []\n",
    "    def __len__(self):\n",
    "        return len(self.tokens)\n",
    "    def __getitem__(self, position):\n",
    "        return self.tokens[position]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "By implementing `__len__` and `__getitem__` [double-under functions](https://www.geeksforgeeks.org/dunder-magic-methods-python/) we got the ability to iterate through the Doc's tokens with a simple for as below. This is thanks to the Python datamodel. It's outside the scope of this post, but learning to leverage the datamodel will pay dividends on your effectiveness in Python. The first chapter of [Fluent Python](https://learning.oreilly.com/library/view/fluent-python/9781491946237/) introduces it in the first chapter in a very neat way. If you like video format more, [James Powell](https://www.youtube.com/watch?v=AmHE0kZhLIQ) got you covered."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "doc = Doc(\"Today I ate garbonzo beans\")\n",
    "for token in doc:\n",
    "    print(token)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Today\n",
      "I\n",
      "ate\n",
      "garbonzo\n",
      "beans\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A `Span` is a slice of a `Doc`. Usually it can.. span multiple tokens, but today I have a feeling that all the spans we'll look at will match exactly one token. Also, in our case the spans will be always labeled."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Span(NamedTuple):\n",
    "    position: int\n",
    "    label: str\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# skweak functions\n",
    "\n",
    "Now, skweak provides us with some very interesting objects. One is a `FunctionAnnotator`. This takes a function that returns a list of spans from a document and attaches these spans to the given document. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class FunctionAnnotator:\n",
    "    def __init__(self, function: Callable[[Doc], Iterable[Span]]):\n",
    "        self.find_spans = function\n",
    "\t\t\n",
    "    def __call__(self, doc: Doc) -> Doc:\n",
    "        # We start by clearing all existing annotations\n",
    "        doc.spans = []\n",
    "\n",
    "        for position, label in self.find_spans(doc):\n",
    "            doc.spans.append(Span(position, label))\n",
    "\n",
    "        return doc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def animal_labeling_function(doc: Doc) -> Generator[Span, None, None]:\n",
    "    for position, token in enumerate(doc.tokens):\n",
    "        if token.startswith('a'):\n",
    "            yield Span(position, 'ANIMAL')\n",
    "\n",
    "doc = Doc('this animal is some kind of antilope')\n",
    "animal_annotator = FunctionAnnotator(animal_labeling_function)\n",
    "doc = animal_annotator(doc)\n",
    "\n",
    "print(doc.spans)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Span(position=1, label='ANIMAL'), Span(position=6, label='ANIMAL')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `FunctionAnnotatorAggregator` takes multiple annotator functions and combines them in some fancy way. We will implement it so our documents to have a maximum of one label per span. We will also sort them by the order of appearance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class FunctionAnnotatorAggregator:\n",
    "    def __init__(self, annotators: Iterable[FunctionAnnotator]) -> None:\n",
    "        self.annotators = annotators\n",
    "    \n",
    "    def __call__(self, doc: Doc) -> Doc:\n",
    "        spans_dict = dict()\n",
    "        for annotator in self.annotators:\n",
    "            for span in annotator(doc).spans:\n",
    "                spans_dict[span.position] = span.label\n",
    "        \n",
    "        \n",
    "        doc.spans = []\n",
    "        for position, label in spans_dict.items():\n",
    "            doc.spans.append(Span(position, label))\n",
    "        doc.spans.sort()\n",
    "        \n",
    "        return doc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def verb_labeling_function(doc: Doc) -> Generator[Span, None, None]:\n",
    "    for position, token in enumerate(doc.tokens):\n",
    "        if token in ['is', 'has']:\n",
    "            yield Span(position, 'VERB')\n",
    "\n",
    "verb_annotator = FunctionAnnotator(verb_labeling_function)\n",
    "\n",
    "aggregated_annotator = FunctionAnnotatorAggregator([animal_annotator, verb_annotator])\n",
    "\n",
    "doc = aggregated_annotator(doc)\n",
    "\n",
    "print(doc.spans)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Span(position=1, label='ANIMAL'), Span(position=2, label='VERB'), Span(position=6, label='ANIMAL')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The problem\n",
    "\n",
    "All nice and dandy, the packages are well implemented and work as expected! \n",
    "Now, since the aggregator is so fancy, we may wish to programatically generate some labeling functions from a list of excellent heuristic parameters\n",
    "<a id='problem_cell'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "heuristic_parameters = [\n",
    "    ('M', 'MAMMAL'),\n",
    "    ('F', 'FISH'),\n",
    "    ('B', 'BIRD')\n",
    "    ]\n",
    "\n",
    "labeling_functions = []\n",
    "for strats_with, label in heuristic_parameters:\n",
    "    def labeling_function(doc: Doc) -> Generator[Span, None, None]:\n",
    "        for position, word in enumerate(doc.tokens):\n",
    "            if word.startswith(strats_with):\n",
    "                yield Span(position, label)\n",
    "    labeling_functions += [labeling_function]\n",
    "\n",
    "strats_with, label = 'B', 'BOVINE'\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='problem_cell_2'></a>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "doc = Doc(\"Monkeys are red. Firefish are blue; Besra is a bird and so are you\")\n",
    "\n",
    "def print_spans_from_labelers(doc, labeling_functions):\n",
    "    annotators = [FunctionAnnotator(labeling_function) for labeling_function in labeling_functions]\n",
    "    aggregated_annotator = FunctionAnnotatorAggregator(annotators)\n",
    "\n",
    "    doc = aggregated_annotator(doc)\n",
    "\n",
    "    print(doc.spans)\n",
    "print_spans_from_labelers(doc, labeling_functions)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Span(position=6, label='BOVINE')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "What happened? It seems that only the last function was applied. Let's look at the `labeling_functions`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "for labeling_function in labeling_functions:\n",
    "    print(labeling_functions)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[<function labeling_function at 0x7fd21437ac10>, <function labeling_function at 0x7fd21437aca0>, <function labeling_function at 0x7fd21437ad30>]\n",
      "[<function labeling_function at 0x7fd21437ac10>, <function labeling_function at 0x7fd21437aca0>, <function labeling_function at 0x7fd21437ad30>]\n",
      "[<function labeling_function at 0x7fd21437ac10>, <function labeling_function at 0x7fd21437aca0>, <function labeling_function at 0x7fd21437ad30>]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "They point to the same memory address. This is because Python redefines functions in place. \n",
    "But this is not the only problem. Let's rewrite this with lambda functions. \n",
    "\n",
    "*Note* if you haven't worked with list comprehensions before: don't worry about it; think of the code below as a way to create a new function without replacing the existing function with the same name"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "labeling_functions = [\n",
    "                        lambda doc: \n",
    "                            ( # this is also a generator in Python; it's the same syntax as list comprehension\n",
    "                            # but we use round braces instead of square ones\n",
    "                                Span(position, label) \n",
    "                                    for position, word in enumerate(doc.tokens) \n",
    "                                    if word.startswith(strats_with)\n",
    "                            )\n",
    "                        for strats_with, label in heuristic_parameters\n",
    "                    ]\n",
    "\n",
    "for labeling_function in labeling_functions:\n",
    "    print(labeling_function)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<function <listcomp>.<lambda> at 0x7fd21438d670>\n",
      "<function <listcomp>.<lambda> at 0x7fd21438d700>\n",
      "<function <listcomp>.<lambda> at 0x7fd21438d790>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "But when we want to print the function the problem stays."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "print_spans_from_labelers(doc, labeling_functions)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Span(position=6, label='BIRD')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is because of scoping. The problem is that, since we didn't declare strats_with, label in the lambda body or parameters, the lambdas will always look in the scope immediately outside them and they will find the last values that `strats_with`, `label` had.\n",
    "If you come from other languages it might be strange to you, but Python doesn't create a new scope for the `for` body. Instead it uses the same local scope. This is why `strats_with, label = 'B', 'BOVINE'` in cell [8](#problem_cell) produced cell [9](#problem_cell_2) to display the label as 'BOVINE'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "But be not affraid! There is a solution:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def function_closure(strats_with, label):\n",
    "    def labeling_function(doc: Doc) -> Generator[Span, None, None]:\n",
    "        for position, word in enumerate(doc.tokens):\n",
    "            if word.startswith(strats_with):\n",
    "                yield Span(position, label)\n",
    "    return labeling_function\n",
    "\n",
    "labeling_functions = [function_closure(strats_with, label) for strats_with, label in heuristic_parameters]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, when we get the annotators things go as expected."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "print_spans_from_labelers(doc, labeling_functions)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Span(position=0, label='MAMMAL'), Span(position=3, label='FISH'), Span(position=6, label='BIRD')]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, what happened? Well, this time we created a runtime around the labeling function and put strats_with, label in it.\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('3.9.5': pyenv)"
  },
  "interpreter": {
   "hash": "adf093301c14a63c6539f58cf0b8916c00ba44ee06fa6d5252f125346225c63b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}